{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "synglabs",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gED2byx7b428",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from skimage import transform, io, img_as_float, exposure\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71bp-Shadv7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading the data\n",
        "\n",
        "def loadDataGeneral(df, path, im_shape):\n",
        "    \"\"\"Function for loading arbitrary data in standard formats\"\"\"\n",
        "    X, y = [], []\n",
        "    for i, item in df.iterrows():\n",
        "        img = img_as_float(io.imread(path + item[0]))\n",
        "        mask = io.imread(path + item[1])\n",
        "        img = transform.resize(img, im_shape)\n",
        "        img = exposure.equalize_hist(img)\n",
        "        img = np.expand_dims(img, -1)\n",
        "        mask = transform.resize(mask, im_shape)\n",
        "        mask = np.expand_dims(mask, -1)\n",
        "        X.append(img)\n",
        "        y.append(mask)\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    X -= X.mean()\n",
        "    X /= X.std()\n",
        "\n",
        "    print ('### Dataset loaded')\n",
        "    return X, y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zer7pcENT-PG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "c4bc682f-8b0e-42cb-93e3-fa35d1e64fda"
      },
      "source": [
        "#building the UNet model\n",
        "\n",
        "def build_UNet2D_4L(inp_shape, k_size=3):\n",
        "    merge_axis = -1 # Feature maps are concatenated along last axis (for tf backend)\n",
        "    data = Input(shape=inp_shape)\n",
        "    conv1 = Convolution2D(filters=32, kernel_size=k_size, padding='same', activation='relu')(data)\n",
        "    conv1 = Convolution2D(filters=32, kernel_size=k_size, padding='same', activation='relu')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Convolution2D(filters=64, kernel_size=k_size, padding='same', activation='relu')(pool1)\n",
        "    conv2 = Convolution2D(filters=64, kernel_size=k_size, padding='same', activation='relu')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Convolution2D(filters=64, kernel_size=k_size, padding='same', activation='relu')(pool2)\n",
        "    conv3 = Convolution2D(filters=64, kernel_size=k_size, padding='same', activation='relu')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Convolution2D(filters=128, kernel_size=k_size, padding='same', activation='relu')(pool3)\n",
        "    conv4 = Convolution2D(filters=128, kernel_size=k_size, padding='same', activation='relu')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Convolution2D(filters=256, kernel_size=k_size, padding='same', activation='relu')(pool4)\n",
        "\n",
        "    up1 = UpSampling2D(size=(2, 2))(conv5)\n",
        "    conv6 = Convolution2D(filters=256, kernel_size=k_size, padding='same', activation='relu')(up1)\n",
        "    conv6 = Convolution2D(filters=256, kernel_size=k_size, padding='same', activation='relu')(conv6)\n",
        "    merged1 = concatenate([conv4, conv6], axis=merge_axis)\n",
        "    conv6 = Convolution2D(filters=256, kernel_size=k_size, padding='same', activation='relu')(merged1)\n",
        "\n",
        "    up2 = UpSampling2D(size=(2, 2))(conv6)\n",
        "    conv7 = Convolution2D(filters=256, kernel_size=k_size, padding='same', activation='relu')(up2)\n",
        "    conv7 = Convolution2D(filters=256, kernel_size=k_size, padding='same', activation='relu')(conv7)\n",
        "    merged2 = concatenate([conv3, conv7], axis=merge_axis)\n",
        "    conv7 = Convolution2D(filters=256, kernel_size=k_size, padding='same', activation='relu')(merged2)\n",
        "\n",
        "    up3 = UpSampling2D(size=(2, 2))(conv7)\n",
        "    conv8 = Convolution2D(filters=128, kernel_size=k_size, padding='same', activation='relu')(up3)\n",
        "    conv8 = Convolution2D(filters=128, kernel_size=k_size, padding='same', activation='relu')(conv8)\n",
        "    merged3 = concatenate([conv2, conv8], axis=merge_axis)\n",
        "    conv8 = Convolution2D(filters=128, kernel_size=k_size, padding='same', activation='relu')(merged3)\n",
        "\n",
        "    up4 = UpSampling2D(size=(2, 2))(conv8)\n",
        "    conv9 = Convolution2D(filters=64, kernel_size=k_size, padding='same', activation='relu')(up4)\n",
        "    conv9 = Convolution2D(filters=64, kernel_size=k_size, padding='same', activation='relu')(conv9)\n",
        "    merged4 = concatenate([conv1, conv9], axis=merge_axis)\n",
        "    conv9 = Convolution2D(filters=64, kernel_size=k_size, padding='same', activation='relu')(merged4)\n",
        "\n",
        "    conv10 = Convolution2D(filters=1, kernel_size=k_size, padding='same', activation='sigmoid')(conv9)\n",
        "\n",
        "    output = conv10\n",
        "    model = Model(data, output)\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxQAOqS9V6cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    csv_path = 'https://drive.google.com/drive/u/0/folders/1sIRSJlv8NvU9SiJSFQFauepyUDDgcn0K'\n",
        "    # Path to the folder with images. Images will be read from path + path_from_csv\n",
        "    path = csv_path[:csv_path.rfind('/')] + '/'\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    # Shuffle rows in dataframe. Random state is set for reproducibility.\n",
        "    df = df.sample(frac=1, random_state=23)\n",
        "    n_train = int(len(df))\n",
        "    df_train = df[:n_train]\n",
        "    df_val = df[n_train:]\n",
        "\n",
        "    # Load training and validation data\n",
        "    im_shape = (256, 256)\n",
        "    X_train, y_train = loadData(df_train, path, im_shape)\n",
        "    X_val, y_val = loadData(df_val, path, im_shape)\n",
        "\n",
        "\n",
        "    inp_shape = X_train[0].shape\n",
        "    UNet = build_UNet2D_4L(inp_shape)\n",
        "    UNet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    plot_model(UNet, 'model.png', show_shapes=True)\n",
        "\n",
        "\n",
        "    model_file_format = 'model.{epoch:03d}.hdf5'\n",
        "    print (model_file_format)\n",
        "    checkpointer = ModelCheckpoint(model_file_format, period=10)\n",
        "\n",
        "    train_gen = ImageDataGenerator(rotation_range=10,\n",
        "                                   width_shift_range=0.1,\n",
        "                                   height_shift_range=0.1,\n",
        "                                   rescale=1.,\n",
        "                                   zoom_range=0.2,\n",
        "                                   fill_mode='nearest',\n",
        "                                   cval=0)\n",
        "\n",
        "    test_gen = ImageDataGenerator(rescale=1.)\n",
        "\n",
        "    batch_size = 8\n",
        "    UNet.fit_generator(train_gen.flow(X_train, y_train, batch_size),\n",
        "                       steps_per_epoch=(X_train.shape[0] + batch_size - 1) // batch_size,\n",
        "                       epochs=100,\n",
        "                       callbacks=[checkpointer],\n",
        "                       validation_data=test_gen.flow(X_val, y_val),\n",
        "                       validation_steps=(X_val.shape[0] + batch_size - 1) // batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97EZju21hSTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    \"\"\"Returns image with GT lung field outlined with red, predicted lung field\n",
        "    filled with blue.\"\"\"\n",
        "\n",
        "def masked(img, gt, mask, alpha=1):\n",
        "    rows, cols = img.shape\n",
        "    color_mask = np.zeros((rows, cols, 3))\n",
        "    boundary = morphology.dilation(gt, morphology.disk(3)) - gt\n",
        "    color_mask[mask == 1] = [0, 0, 1]\n",
        "    color_mask[boundary == 1] = [1, 0, 0]\n",
        "    img_color = np.dstack((img, img, img))\n",
        "\n",
        "    img_hsv = color.rgb2hsv(img_color)\n",
        "    color_mask_hsv = color.rgb2hsv(color_mask)\n",
        "\n",
        "    img_hsv[..., 0] = color_mask_hsv[..., 0]\n",
        "    img_hsv[..., 1] = color_mask_hsv[..., 1] * alpha\n",
        "\n",
        "    img_masked = color.hsv2rgb(img_hsv)\n",
        "    return img_masked\n",
        "\n",
        "def remove_small_regions(img, size):\n",
        "    img = morphology.remove_small_objects(img, size)\n",
        "    img = morphology.remove_small_holes(img, size)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZdf_HsalKch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}